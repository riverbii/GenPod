import argparse
import logging
import multiprocessing
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
# sys.path.insert(0, str(Path(__file__).parent))

from .text_processor import process_markdown_file


def setup_logging(log_file=None):
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    if log_file is None:
        # é»˜è®¤æ—¥å¿—æ–‡ä»¶ï¼šlogs/batch_generate_YYYYMMDD.log
        # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ logs ç›®å½•
        log_dir = Path.cwd() / "logs"
        log_dir.mkdir(exist_ok=True)
        log_file = log_dir / f"batch_generate_{datetime.now().strftime('%Y%m%d')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)


def generate_segment(args_tuple):
    """ç”Ÿæˆå•ä¸ªæ®µè½éŸ³é¢‘ï¼ˆç”¨äºå¤šè¿›ç¨‹ï¼‰"""
    segment_text, segment_index, output_dir, md_dir, seed = args_tuple
    
    # ç»Ÿè®¡æ–‡å­—æ•°é‡
    import re
    text_clean = re.sub(r'\[.*?\]', '', segment_text)
    text_clean = re.sub(r'\s+', '', text_clean)
    text_chars = len(text_clean)
    
    # mdæ–‡ä»¶å’Œwavæ–‡ä»¶åˆ†å¼€å­˜æ”¾
    # mdæ–‡ä»¶å­˜æ”¾åœ¨md_dirç›®å½•
    md_file = Path(md_dir) / f"segment_{segment_index:03d}.md"
    md_file.parent.mkdir(parents=True, exist_ok=True)
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(segment_text)
    
    # wavæ–‡ä»¶å­˜æ”¾åœ¨output_dirç›®å½•
    output_file = Path(output_dir) / f"segment_{segment_index:03d}.wav"
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # è°ƒç”¨ generate_podcast.py
    cmd = [
        sys.executable,
        "-m", "genpod.generate_podcast",
        str(md_file),
        "-o", str(output_file),
        "-v", str(seed)
    ]
    
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd=Path.cwd()
        )
        elapsed_time = time.time() - start_time
        
        if result.returncode == 0:
            print(f"âœ… æ®µè½ {segment_index} ç”Ÿæˆå®Œæˆ ({text_chars} å­—, {elapsed_time:.2f}ç§’)")
            return (segment_index, str(output_file), text_chars, elapsed_time)
        else:
            print(f"âŒ æ®µè½ {segment_index} ç”Ÿæˆå¤±è´¥: {result.stderr}")
            return None
    except Exception as e:
        print(f"âŒ æ®µè½ {segment_index} ç”Ÿæˆå‡ºé”™: {e}")
        return None


def batch_generate(input_file, output_dir, seed=7470000, num_workers=None, min_chars=50, max_chars=200, logger=None):
    """å¹¶è¡Œç”Ÿæˆå¤šä¸ªæ®µè½éŸ³é¢‘
    
    å‚æ•°ï¼š
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        seed: éšæœºç§å­
        num_workers: å¹¶è¡Œè¿›ç¨‹æ•°
        min_chars: æœ€å°å­—æ•°ï¼ˆé»˜è®¤50ï¼‰ï¼Œä½äºæ­¤å€¼ä¼šåˆå¹¶å¤šä¸ªæ®µè½
        max_chars: æœ€å¤§å­—æ•°ï¼ˆé»˜è®¤200ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼ä¼šæ‹†åˆ†æ®µè½
        logger: æ—¥å¿—è®°å½•å™¨
    """
    if logger is None:
        logger = setup_logging()
    
    total_start_time = time.time()
    
    # å¤„ç†æ–‡æœ¬
    logger.info(f"å¼€å§‹å¤„ç†æ–‡æœ¬æ–‡ä»¶: {input_file}")
    print("ğŸ“ æ­£åœ¨å¤„ç†æ–‡æœ¬...")
    print(f"   åˆå¹¶ç­–ç•¥ï¼šæœ€å° {min_chars} å­—ï¼Œæœ€å¤§ {max_chars} å­—")
    paragraphs = process_markdown_file(input_file, min_chars, max_chars)
    print(f"âœ… æ–‡æœ¬å¤„ç†å®Œæˆï¼Œå…± {len(paragraphs)} ä¸ªæ®µè½")
    logger.info(f"æ–‡æœ¬å¤„ç†å®Œæˆï¼Œå…± {len(paragraphs)} ä¸ªæ®µè½")
    
    # ç»Ÿè®¡æ€»å­—æ•°
    import re
    total_chars = 0
    for i, para in enumerate(paragraphs, 1):
        text_clean = re.sub(r'\[.*?\]', '', para)
        text_clean = re.sub(r'\s+', '', text_clean)
        char_count = len(text_clean)
        total_chars += char_count
        print(f"   æ®µè½ {i}: {char_count} å­—")
        logger.info(f"æ®µè½ {i:03d}: {char_count} å­—")
    
    logger.info(f"æ€»æ–‡å­—æ•°: {total_chars} å­—")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºmdæ–‡ä»¶ç›®å½•ï¼ˆä¸wavæ–‡ä»¶åˆ†å¼€ï¼‰
    md_dir = Path(output_dir).parent / f"{Path(output_dir).name}_md"
    md_dir.mkdir(parents=True, exist_ok=True)
    
    # å‡†å¤‡å‚æ•°
    if num_workers is None:
        # é™åˆ¶æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°ä¸º 2ï¼Œé¿å…æ¯ä¸ªè¿›ç¨‹éƒ½é‡æ–°åŠ è½½æ¨¡å‹å¯¼è‡´å†…å­˜å ç”¨è¿‡é«˜
        # è™½ç„¶æ€»æ—¶é—´å¯èƒ½ç¨é•¿ï¼Œä½†ç³»ç»Ÿèµ„æºå ç”¨æ›´åˆç†ï¼Œæ¯ä¸ªè¿›ç¨‹çš„åŠ è½½æ—¶é—´ä¹Ÿä¼šåˆ†æ•£
        num_workers = min(2, len(paragraphs))
    
    args_list = [
        (para, idx, output_dir, md_dir, seed)
        for idx, para in enumerate(paragraphs, 1)
    ]
    
    # å¹¶è¡Œç”Ÿæˆ
    logger.info(f"å¼€å§‹å¹¶è¡Œç”ŸæˆéŸ³é¢‘ - è¿›ç¨‹æ•°: {num_workers}, æ€»æ®µè½æ•°: {len(paragraphs)}")
    print(f"ğŸ¤ å¼€å§‹å¹¶è¡Œç”ŸæˆéŸ³é¢‘ï¼ˆä½¿ç”¨ {num_workers} ä¸ªè¿›ç¨‹ï¼‰...")
    print("ğŸ’¡ æç¤ºï¼šæ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½åˆ°æœ¬åœ°ï¼Œæ¯ä¸ªè¿›ç¨‹ä¼šå¤ç”¨å·²ä¸‹è½½çš„æ¨¡å‹")
    print("ğŸ’¡ æç¤ºï¼šé™åˆ¶å¹¶è¡Œè¿›ç¨‹æ•°ä¸º 2ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜")
    
    generation_start_time = time.time()
    with multiprocessing.Pool(processes=num_workers) as pool:
        results = pool.map(generate_segment, args_list)
    generation_time = time.time() - generation_start_time
    
    # æ”¶é›†æˆåŠŸçš„ç»“æœï¼ŒæŒ‰ç´¢å¼•æ’åº
    successful_results = sorted(
        [r for r in results if r is not None],
        key=lambda x: x[0]
    )
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_success_chars = sum(r[2] for r in successful_results if len(r) > 2)
    total_success_time = sum(r[3] for r in successful_results if len(r) > 3)
    avg_time_per_segment = total_success_time / len(successful_results) if successful_results else 0
    avg_chars_per_segment = total_success_chars / len(successful_results) if successful_results else 0
    
    total_time = time.time() - total_start_time
    
    # è®°å½•ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"æ‰¹é‡ç”Ÿæˆå®Œæˆ - æˆåŠŸ: {len(successful_results)}/{len(paragraphs)} ä¸ªæ®µè½")
    logger.info(f"ç»Ÿè®¡ä¿¡æ¯:")
    logger.info(f"  - æ€»æ–‡å­—æ•°: {total_success_chars} å­—")
    logger.info(f"  - æ€»ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
    logger.info(f"  - æ€»è€—æ—¶: {total_time:.2f} ç§’")
    logger.info(f"  - å¹³å‡æ¯æ®µè½è€—æ—¶: {avg_time_per_segment:.2f} ç§’")
    logger.info(f"  - å¹³å‡æ¯æ®µè½å­—æ•°: {avg_chars_per_segment:.1f} å­—")
    logger.info(f"  - å¹³å‡ç”Ÿæˆé€Ÿåº¦: {total_success_chars/generation_time:.2f} å­—/ç§’" if generation_time > 0 else "  - å¹³å‡ç”Ÿæˆé€Ÿåº¦: N/A")
    
    print(f"\nâœ… æ‰¹é‡ç”Ÿæˆå®Œæˆï¼æˆåŠŸç”Ÿæˆ {len(successful_results)}/{len(paragraphs)} ä¸ªæ®µè½")
    print(f"ğŸ“Š ç»Ÿè®¡: {total_success_chars} å­—, {generation_time:.2f}ç§’ç”Ÿæˆ, {total_time:.2f}ç§’æ€»è€—æ—¶")
    print(f"ğŸ“Š å¹³å‡: {avg_chars_per_segment:.1f} å­—/æ®µè½, {avg_time_per_segment:.2f}ç§’/æ®µè½")
    
    # è¿”å›æ–‡ä»¶åˆ—è¡¨
    return [r[1] for r in successful_results]


def main():
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡å¹¶è¡Œç”Ÿæˆæ’­å®¢æ®µè½éŸ³é¢‘"
    )
    
    parser.add_argument(
        'input_file',
        type=str,
        help='è¾“å…¥çš„ Markdown æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-o', '--output-dir',
        type=str,
        default='output/segments',
        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šoutput/segmentsï¼‰'
    )
    
    parser.add_argument(
        '-v', '--voice',
        type=str,
        default='7470000',
        help='éšæœºç§å­ï¼ˆseedï¼‰ï¼Œé»˜è®¤ï¼š7470000'
    )
    
    parser.add_argument(
        '-j', '--jobs',
        type=int,
        default=None,
        help='å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š2ï¼Œé¿å…æ¯ä¸ªè¿›ç¨‹éƒ½é‡æ–°åŠ è½½æ¨¡å‹å¯¼è‡´å†…å­˜å ç”¨è¿‡é«˜ï¼‰'
    )
    
    parser.add_argument(
        '--min-chars',
        type=int,
        default=50,
        help='æœ€å°å­—æ•°ï¼ˆé»˜è®¤ï¼š50ï¼‰ï¼Œä½äºæ­¤å€¼ä¼šåˆå¹¶å¤šä¸ªæ®µè½'
    )
    
    parser.add_argument(
        '--max-chars',
        type=int,
        default=200,
        help='æœ€å¤§å­—æ•°ï¼ˆé»˜è®¤ï¼š200ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼ä¼šæ‹†åˆ†æ®µè½'
    )
    
    parser.add_argument(
        '--log-file',
        type=str,
        default=None,
        help='æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šlogs/batch_generate_YYYYMMDD.logï¼‰'
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.log_file)
    logger.info(f"æ‰¹é‡ç”Ÿæˆå¼€å§‹ - è¾“å…¥æ–‡ä»¶: {args.input_file}, è¾“å‡ºç›®å½•: {args.output_dir}")
    
    batch_generate(
        args.input_file,
        args.output_dir,
        seed=int(args.voice) if args.voice.isdigit() else 7470000,
        num_workers=args.jobs,
        min_chars=args.min_chars,
        max_chars=args.max_chars,
        logger=logger
    )


if __name__ == "__main__":
    main()
