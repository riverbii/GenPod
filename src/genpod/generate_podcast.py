import argparse
import logging
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path

import ChatTTS
import torch
import torchaudio

from .pronunciations import DEFAULT_PRONUNCIATIONS


def setup_logging(log_file=None):
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    if log_file is None:
        # é»˜è®¤æ—¥å¿—æ–‡ä»¶ï¼šlogs/generate_podcast_YYYYMMDD.log
        # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ logs ç›®å½•
        log_dir = Path.cwd() / "logs"
        log_dir.mkdir(exist_ok=True)
        log_file = log_dir / f"generate_podcast_{datetime.now().strftime('%Y%m%d')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)


def count_text_chars(text):
    """ç»Ÿè®¡å®é™…æ–‡å­—æ•°é‡ï¼ˆå»é™¤æ ‡è®°å’Œæ§åˆ¶å­—ç¬¦ï¼‰"""
    # ç§»é™¤ ChatTTS æ ‡è®°ï¼š[uv_break], [laugh], [oral] ç­‰
    text_clean = re.sub(r'\[.*?\]', '', text)
    # ç§»é™¤ç©ºç™½å­—ç¬¦
    text_clean = re.sub(r'\s+', '', text_clean)
    return len(text_clean)


def read_markdown_file(file_path):
    """è¯»å– markdown æ–‡ä»¶å¹¶æå–æ–‡æœ¬å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")
        sys.exit(1)


# å…¨å±€ ChatTTS å®ä¾‹ï¼ˆé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰
_chat_instance = None

def get_chat_instance():
    """è·å– ChatTTS å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _chat_instance
    if _chat_instance is None:
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
        # ä¼˜å…ˆæŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„ asset
        project_root = Path.cwd()
        asset_dir = project_root / "asset"
        local_model_exists = (
            (asset_dir / "Decoder.safetensors").exists() and
            (asset_dir / "DVAE.safetensors").exists() and
            (asset_dir / "Embed.safetensors").exists() and
            (asset_dir / "Vocos.safetensors").exists() and
            (asset_dir / "gpt" / "config.json").exists() and
            (asset_dir / "gpt" / "model.safetensors").exists() and
            (asset_dir / "tokenizer" / "tokenizer.json").exists()
        )
        
        if local_model_exists:
            print("ğŸ”„ æ­£åœ¨åŠ è½½ ChatTTS æ¨¡å‹ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶ï¼‰...")
            # ChatTTS ä¼šè‡ªåŠ¨æ£€æµ‹å½“å‰ç›®å½•ä¸‹çš„ asset æ–‡ä»¶å¤¹
            # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œç¡®ä¿èƒ½æ‰¾åˆ° asset ç›®å½•
            original_cwd = os.getcwd()
            try:
                os.chdir(str(project_root))
                _chat_instance = ChatTTS.Chat()
                _chat_instance.load(compile=False)  # compile=False å¯ä»¥åŠ å¿«åŠ è½½é€Ÿåº¦
                print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼ˆä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼‰")
            finally:
                os.chdir(original_cwd)
        else:
            print("ğŸ”„ æ­£åœ¨åŠ è½½ ChatTTS æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä»ç½‘ç»œä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼‰...")
            print("ğŸ’¡ æç¤ºï¼šè¿è¡Œ download_models.sh å¯ä»¥é¢„å…ˆä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ï¼ŒåŠ å¿«åç»­åŠ è½½é€Ÿåº¦")
            _chat_instance = ChatTTS.Chat()
            _chat_instance.load(compile=False)  # compile=False å¯ä»¥åŠ å¿«åŠ è½½é€Ÿåº¦
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return _chat_instance


def apply_pronunciations(text, dictionary):
    """Apply pronunciation replacements from dictionary (case-insensitive for keys)"""
    if not dictionary:
        return text
        
    for word, replacement in dictionary.items():
        # Use simple string replacement for now, or regex for whole words
        # Replaces all occurrences, case-insensitive logic handled by user input typically
        # But here we do simple replace to keep it predictable
        text = text.replace(str(word), str(replacement))
    return text


def generate_audio(text, voice, output_file, rate=None, pitch=None, logger=None, pronunciations=None):
    """ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨ ChatTTSï¼‰"""
    if logger is None:
        logger = logging.getLogger(__name__)
    
    # Check if text is empty
    if not text or not text.strip():
        logger.warning(f"Empty text for output {output_file}, skipping generation.")
        return

    # Apply pronunciation replacements
    # Merge user provided pronunciations with defaults
    # User config overrides defaults
    combined_pronunciations = DEFAULT_PRONUNCIATIONS.copy()
    if pronunciations:
        combined_pronunciations.update(pronunciations)

    # Use combined dictionary
    if combined_pronunciations:
        original_text = text
        text = apply_pronunciations(text, combined_pronunciations)
        if text != original_text:
            logger.info(f"  Applied pronunciation fixes. Text modified.")

    chat = get_chat_instance()
    
    # ç»Ÿè®¡æ–‡å­—æ•°é‡
    text_chars = count_text_chars(text)
    raw_chars = len(text)
    
    # å°† voice å‚æ•°è½¬æ¢ä¸º seed
    try:
        seed = int(voice) if voice.isdigit() else 2222
    except (ValueError, AttributeError):
        seed = 2222
    
    # ChatTTS ä¸æ”¯æŒ rate å’Œ pitch å‚æ•°ï¼Œç»™å‡ºæç¤º
    if rate or pitch:
        logger.warning("ChatTTS ä¸æ”¯æŒè¯­é€Ÿå’ŒéŸ³è°ƒè°ƒæ•´ï¼Œè¿™äº›å‚æ•°å°†è¢«å¿½ç•¥")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(seed)
    
    # ç”Ÿæˆéšæœºspeaker embeddingï¼ˆç”¨äºæ§åˆ¶éŸ³è‰²å’Œæ€§åˆ«ï¼‰
    spk_emb = chat.sample_random_speaker()
    
    logger.info(f"å¼€å§‹ç”ŸæˆéŸ³é¢‘ - seed: {seed}, åŸå§‹æ–‡æœ¬é•¿åº¦: {raw_chars} å­—ç¬¦, å®é™…æ–‡å­—æ•°: {text_chars} å­—")
    print(f"ğŸ¤ æ­£åœ¨ç”ŸæˆéŸ³é¢‘ï¼ˆseed: {seed}ï¼‰...")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # è®¾ç½®å‚æ•°ä»¥é¿å…æ–‡æœ¬è¢«æˆªæ–­
    params_refine = chat.RefineTextParams(max_new_token=8192)
    params_infer = chat.InferCodeParams(spk_emb=spk_emb, max_new_token=8192)
    
    wavs = chat.infer(
        [text], 
        use_decoder=True, 
        params_refine_text=params_refine,
        params_infer_code=params_infer,
        split_text=True,
        max_split_batch=1
    )
    
    # è®°å½•ç”Ÿæˆæ—¶é—´
    generation_time = time.time() - start_time
    
    # è½¬æ¢ä¸º torch tensor
    wav_array = wavs[0]
    wav_tensor = torch.from_numpy(wav_array)
    
    # è®¡ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    audio_duration = len(wav_array) / 24000  # é‡‡æ ·ç‡ 24000
    
    # ç¡®ä¿æ˜¯ 2D tensor (channels, samples)
    if len(wav_tensor.shape) == 1:
        wav_tensor = wav_tensor.unsqueeze(0)
    elif len(wav_tensor.shape) > 2:
        wav_tensor = wav_tensor[0] if wav_tensor.shape[0] == 1 else wav_tensor.squeeze()
    
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶æ‰©å±•åä¸º .wav
    output_path = Path(output_file)
    if output_path.suffix != '.wav':
        output_file = str(output_path.with_suffix('.wav'))
    
    # ä¿å­˜éŸ³é¢‘ï¼ˆé‡‡æ ·ç‡ 24000ï¼‰
    save_start_time = time.time()
    if wav_tensor.shape[0] > wav_tensor.shape[-1]:
        wav_tensor = wav_tensor.T
    torchaudio.save(output_file, wav_tensor, 24000)
    save_time = time.time() - save_start_time
    
    total_time = time.time() - start_time
    
    # è®¡ç®—é€Ÿåº¦æŒ‡æ ‡
    chars_per_second = text_chars / generation_time if generation_time > 0 else 0
    audio_ratio = audio_duration / generation_time if generation_time > 0 else 0
    
    # è®°å½•ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"éŸ³é¢‘ç”Ÿæˆå®Œæˆ - æ–‡ä»¶: {output_file}")
    logger.info(f"  ç»Ÿè®¡ä¿¡æ¯:")
    logger.info(f"    - åŸå§‹æ–‡æœ¬é•¿åº¦: {raw_chars} å­—ç¬¦")
    logger.info(f"    - å®é™…æ–‡å­—æ•°: {text_chars} å­—")
    logger.info(f"    - ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
    logger.info(f"    - ä¿å­˜è€—æ—¶: {save_time:.2f} ç§’")
    logger.info(f"    - æ€»è€—æ—¶: {total_time:.2f} ç§’")
    logger.info(f"    - éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f} ç§’")
    logger.info(f"    - ç”Ÿæˆé€Ÿåº¦: {chars_per_second:.2f} å­—/ç§’")
    logger.info(f"    - éŸ³é¢‘/ç”Ÿæˆæ¯”: {audio_ratio:.2f}x")
    
    print(f"âœ… ChatTTS ç”Ÿæˆå®Œæ¯•: {output_file}")
    print(f"ğŸ“Š ç»Ÿè®¡: {text_chars} å­—, {generation_time:.2f}ç§’ç”Ÿæˆ, {audio_duration:.2f}ç§’éŸ³é¢‘, {chars_per_second:.2f}å­—/ç§’")


def main():
    parser = argparse.ArgumentParser(
        description="ä» Markdown æ–‡ä»¶ç”Ÿæˆæ’­å®¢éŸ³é¢‘",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python generate_podcast.py script.md
  python generate_podcast.py script.md -o output.wav
  python generate_podcast.py script.md -v 2222
  python generate_podcast.py script.md -v 3333
        """
    )
    
    parser.add_argument(
        'input_file',
        type=str,
        help='è¾“å…¥çš„ Markdown æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-o', '--output',
        type=str,
        default=None,
        help='è¾“å‡ºéŸ³é¢‘æ–‡ä»¶åï¼ˆé»˜è®¤ï¼šè¾“å…¥æ–‡ä»¶å.mp3ï¼‰'
    )
    
    parser.add_argument(
        '-v', '--voice',
        type=str,
        default='2222',
        help='éšæœºç§å­ï¼ˆseedï¼‰ï¼Œç”¨äºæ§åˆ¶éŸ³è‰²ï¼Œé»˜è®¤ï¼š2222'
    )
    
    parser.add_argument(
        '-r', '--rate',
        type=str,
        default=None,
        help='è¯­é€Ÿè°ƒæ•´ï¼ˆChatTTS ä¸æ”¯æŒï¼Œå°†è¢«å¿½ç•¥ï¼‰'
    )
    
    parser.add_argument(
        '-p', '--pitch',
        type=str,
        default=None,
        help='éŸ³è°ƒè°ƒæ•´ï¼ˆChatTTS ä¸æ”¯æŒï¼Œå°†è¢«å¿½ç•¥ï¼‰'
    )
    
    parser.add_argument(
        '--log-file',
        type=str,
        default=None,
        help='æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šlogs/generate_podcast_YYYYMMDD.logï¼‰'
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.log_file)
    logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {args.input_file}")
    
    # è¯»å– markdown æ–‡ä»¶
    text = read_markdown_file(args.input_file)
    
    if not text:
        logger.error("æ–‡ä»¶å†…å®¹ä¸ºç©º")
        print("âŒ è­¦å‘Šï¼šæ–‡ä»¶å†…å®¹ä¸ºç©º")
        sys.exit(1)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤è¾“å‡ºåˆ° output/ ç›®å½•ï¼‰
    if args.output:
        output_file = args.output
    else:
        input_path = Path(args.input_file)
        # ç¡®ä¿ output ç›®å½•å­˜åœ¨
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        output_file = str(output_dir / (input_path.stem + ".mp3"))
    
    text_chars = count_text_chars(text)
    
    print(f"ğŸ“ è¯»å–æ–‡ä»¶: {args.input_file}")
    print(f"ğŸ² éšæœºç§å­: {args.voice}")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦ (å®é™…æ–‡å­—: {text_chars} å­—)")
    print()
    
    logger.info(f"è¾“å…¥æ–‡ä»¶: {args.input_file}, è¾“å‡ºæ–‡ä»¶: {output_file}, seed: {args.voice}")
    logger.info(f"æ–‡æœ¬ç»Ÿè®¡: åŸå§‹é•¿åº¦ {len(text)} å­—ç¬¦, å®é™…æ–‡å­—æ•° {text_chars} å­—")
    
    # ç”ŸæˆéŸ³é¢‘
    generate_audio(text, args.voice, output_file, args.rate, args.pitch, logger)


if __name__ == "__main__":
    main()